{"cells":[{"cell_type":"markdown","id":"e55208c8","metadata":{"id":"e55208c8"},"source":["ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"]},{"cell_type":"code","execution_count":1,"id":"e6c03f63","metadata":{"id":"e6c03f63","executionInfo":{"status":"ok","timestamp":1750732370305,"user_tz":-540,"elapsed":1042,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"id":"nF3sUbtrqYU5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19596,"status":"ok","timestamp":1750732390324,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"},"user_tz":-540},"id":"nF3sUbtrqYU5","outputId":"7a1f51ba-4dee-4713-98b5-54ba61c1bb9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"id":"5441508a","metadata":{"id":"5441508a","executionInfo":{"status":"ok","timestamp":1750732397010,"user_tz":-540,"elapsed":3593,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"}}},"outputs":[],"source":["# 1. ê²°ì¸¡ì¹˜ë§Œ\n","#df1 = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/train_df1.csv\")\n","#val1 = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/val_df1.csv\")\n","# 2. ì´ìƒì¹˜ ì œê±°\n","#df = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/train_df3.csv\")\n","#val2 = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/val_df1.csv\")\n","# 3. ì´ìƒì¹˜ ëŒ€ì²´\n","df = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/test_heat_á„€á…§á†¯á„á…³á†¨á„á…µá„ƒá…¢á„á…¦.csv\")\n","val = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/val_df3.csv\")\n","# 4. ê²°ì¸¡ì¹˜ ì œê±°ë„ ì•ˆí•œ ë²„ì „\n","#df = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/train_df4.csv\")\n","#val = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/val_df4.csv\")\n","test = pd.read_csv(\"/content/gdrive/MyDrive/á„‚á…¢á„‡á…¢á„á…¢á†·_á„‚á…¡á†¯á„Šá…µ_á„ƒá…¦á„‹á…µá„á…¥/test_heat.csv\")"]},{"cell_type":"code","execution_count":4,"id":"ebc10a8d","metadata":{"id":"ebc10a8d","executionInfo":{"status":"ok","timestamp":1750732397022,"user_tz":-540,"elapsed":13,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"}}},"outputs":[],"source":["column_dict = {\n","    'TM' : 'ì‹œê°„',\n","    'branch_ID' : 'ì§€ì‚¬ëª…',\n","    'TA' : 'ê¸°ì˜¨',\n","    'WD' : 'í’í–¥',\n","    'WS' : 'í”™ì†',\n","    'RN_DAY' : 'ì¼ê°•ìˆ˜ëŸ‰',\n","    'RN_HR1' : 'ì‹œê°„ ê°•ìˆ˜ëŸ‰',\n","    'HM' : 'ìƒëŒ€ ìŠµë„',\n","    'SI' : 'ì¼ì‚¬ëŸ‰',\n","    'ta_chi' : 'ì²´ê°ì˜¨ë„',\n","    'heat_demand' : 'ì—´ìˆ˜ìš”'\n","}\n","test.rename(columns=column_dict, inplace=True)"]},{"cell_type":"markdown","id":"dM_KhS3_-bQ6","metadata":{"id":"dM_KhS3_-bQ6"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"wOgpugxnyiVC","metadata":{"id":"wOgpugxnyiVC"},"source":["BI-LSTM\n","íƒ ì„œí”Œë¡œ"]},{"cell_type":"code","execution_count":5,"id":"awZL-kIpTfTK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":8245,"status":"ok","timestamp":1750732408490,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"},"user_tz":-540},"id":"awZL-kIpTfTK","outputId":"b3e8633c-f141-469e-b159-ec76b22e942f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":6,"id":"39060d8f","metadata":{"id":"39060d8f","outputId":"9d79e5f3-5dc3-41b2-c6cc-2cfd1d030639","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750732418157,"user_tz":-540,"elapsed":9665,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"]}],"source":["pip install scikit-learn"]},{"cell_type":"markdown","source":["---------"],"metadata":{"id":"kvLoIlqByKKp"},"id":"kvLoIlqByKKp"},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout, Attention, Concatenate, LayerNormalization, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam\n","\n","# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n","TIMESTEPS = 124\n","LSTM_UNITS = 64\n","DROPOUT_RATE = 0.3\n","LEARNING_RATE = 0.001\n","EPOCHS = 50\n","BATCH_SIZE = 32\n","PATIENCE = 5\n","BASE_FEATURES = ['ê¸°ì˜¨', 'í’í–¥', 'í’ì†', 'ì¼ê°•ìˆ˜ëŸ‰', 'ì‹œê°„ ê°•ìˆ˜ëŸ‰', 'ìƒëŒ€ ìŠµë„', 'ì¼ì‚¬ëŸ‰', 'ì²´ê°ì˜¨ë„', 'ì‹œê°', 'ìš”ì¼1']\n","TARGET = 'ì—´ìˆ˜ìš”'\n","\n","# ì‹œí€€ìŠ¤ ìƒì„± í•¨ìˆ˜\n","def create_sequences(X, y=None, timesteps=TIMESTEPS):\n","    Xs, ys = [], []\n","    for i in range(timesteps, len(X)):\n","        Xs.append(X[i - timesteps:i])\n","        if y is not None:\n","            ys.append(y[i])\n","    return np.array(Xs), (np.array(ys) if y is not None else None)\n","\n","# ì „ì²˜ë¦¬ í•¨ìˆ˜ (ëˆ„ì¶œ ë°©ì§€ + íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ë§)\n","def preprocess_data(df, test):\n","    df_train_enc = pd.get_dummies(df, columns=['ì§€ì‚¬ëª…'])\n","    df_val_enc = pd.get_dummies(test, columns=['ì§€ì‚¬ëª…'])\n","    df_val_enc = df_val_enc.reindex(columns=df_train_enc.columns, fill_value=0)\n","\n","    features = [col for col in df_train_enc.columns if col in BASE_FEATURES or col.startswith('ì§€ì‚¬ëª…_')]\n","\n","    X_train, X_val = df_train_enc[features], df_val_enc[features]\n","    y_train, y_val = df_train_enc[TARGET].values, df_val_enc[TARGET].values\n","\n","    # í”¼ì²˜ ìŠ¤ì¼€ì¼ëŸ¬ (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)\n","    x_scaler = MinMaxScaler()\n","    X_train_scaled = x_scaler.fit_transform(X_train)\n","    X_val_scaled = x_scaler.transform(X_val)\n","\n","    # íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬ (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)\n","    y_scaler = MinMaxScaler()\n","    y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n","    y_val_scaled = y_scaler.transform(y_val.reshape(-1, 1)).flatten()\n","\n","    return X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled, x_scaler, y_scaler, df_val_enc\n","\n","# CNN + BiLSTM + Attention ëª¨ë¸ êµ¬ì„±\n","def build_model(input_shape):\n","    inputs = Input(shape=input_shape)\n","\n","    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n","    x = MaxPooling1D(pool_size=2)(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Bidirectional(LSTM(LSTM_UNITS, return_sequences=True))(x)\n","    x = Dropout(DROPOUT_RATE)(x)\n","    x = Bidirectional(LSTM(LSTM_UNITS // 2, return_sequences=True))(x)\n","    x = Dropout(DROPOUT_RATE * 0.5)(x)\n","\n","    attention = Attention()([x, x])\n","    x = Concatenate()([x, attention])\n","\n","    x = Dense(64, activation='relu')(x)\n","    x = LayerNormalization()(x)\n","    x = Dense(32, activation='relu')(x)\n","    x = Dense(1)(x)\n","\n","    x = x[:, -1, :]  # ì‹œí€€ìŠ¤ ì¤‘ ë§ˆì§€ë§‰ ì‹œì  ê°’ ì¶”ì¶œ\n","    model = Model(inputs, x)\n","    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=['mae'])\n","    return model\n","\n","# í•™ìŠµ ë° í‰ê°€\n","\n","def run_model(df, test):\n","    X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled, x_scaler, y_scaler, val_processed = preprocess_data(df, test)\n","\n","    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled)\n","    X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val_scaled)\n","\n","    model = build_model((TIMESTEPS, X_train_seq.shape[2]))\n","    callbacks = [\n","        EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","    ]\n","\n","    model.fit(\n","        X_train_seq, y_train_seq,\n","        validation_data=(X_val_seq, y_val_seq),\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        callbacks=callbacks,\n","        verbose=1\n","    )\n","    return model, x_scaler, y_scaler, val_processed, (X_val_seq, y_val_seq)\n","\n","# í‰ê°€ í•¨ìˆ˜\n","def evaluate_model(model, X_val_seq, y_val_seq, y_scaler):\n","    y_pred_scaled = model.predict(X_val_seq).flatten()\n","    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n","    y_true = y_scaler.inverse_transform(y_val_seq.reshape(-1, 1)).flatten()\n","\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    r2 = r2_score(y_true, y_pred)\n","\n","    print(f\"ğŸ“Š MAE: {mae:.2f} | RMSE: {rmse:.2f} | RÂ²: {r2:.4f}\")\n","    return y_pred\n","\n","# í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ í•¨ìˆ˜\n","def predict_on_test(model, test_df_raw, x_scaler, y_scaler, reference_df):\n","    test_enc = pd.get_dummies(test_df_raw, columns=['ì§€ì‚¬ëª…'])\n","    test_enc = test_enc.reindex(columns=reference_df.columns, fill_value=0)\n","    features = [col for col in reference_df.columns if col in BASE_FEATURES or col.startswith('ì§€ì‚¬ëª…_')]\n","    X_test = test_enc[features]\n","    X_test_scaled = x_scaler.transform(X_test)\n","\n","    X_test_seq, _ = create_sequences(X_test_scaled)\n","    y_pred_scaled = model.predict(X_test_seq).flatten()\n","    y_pred = y_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n","\n","    result_df = test_df_raw.iloc[TIMESTEPS:].copy()\n","    result_df['ì˜ˆì¸¡_ì—´ìˆ˜ìš”'] = y_pred\n","    return result_df\n"],"metadata":{"id":"My5sEDadyLvu","executionInfo":{"status":"ok","timestamp":1750732528384,"user_tz":-540,"elapsed":4147,"user":{"displayName":"ê¹€ë™í˜„","userId":"04188315936672429012"}}},"id":"My5sEDadyLvu","execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train_scaled, X_val_scaled, y_train_scaled, y_val_scaled, x_scaler, y_scaler, val_processed = preprocess_data(df, val)\n","X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled)\n","X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val_scaled)\n","\n","# 3. ëª¨ë¸ í•™ìŠµ\n","input_shape = (TIMESTEPS, X_train_seq.shape[2])\n","model = build_model(input_shape)\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","]\n","\n","model.fit(\n","    X_train_seq, y_train_seq,\n","    validation_data=(X_val_seq, y_val_seq),\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    callbacks=callbacks,\n","    verbose=1\n",")\n","\n","# 4. í‰ê°€\n","evaluate_model(model, X_val_seq, y_val_seq, y_scaler)\n","\n","# 5. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n","result_df = predict_on_test(model, test, x_scaler, y_scaler, reference_df=val_processed)\n","result_df.to_csv(\"CNN_BiLSTM_Attention_ì˜ˆì¸¡ê²°ê³¼.csv\", index=False)\n","print(\"âœ… ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ â†’ CNN_BiLSTM_Attention_ì˜ˆì¸¡ê²°ê³¼.csv\")"],"metadata":{"id":"kXtj6RE8yiZ6"},"id":"kXtj6RE8yiZ6","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"VhEv2x8HTF3P","metadata":{"id":"VhEv2x8HTF3P"},"source":["\n","\n","---\n","\n"]},{"cell_type":"code","source":["# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n","TIMESTEPS = 124\n","LSTM_UNITS = 64\n","DROPOUT_RATE = 0.3\n","LEARNING_RATE = 0.01\n","BATCH_SIZE = 32\n","EPOCHS = 50\n","PATIENCE = 5\n","\n","\n","# íŠ¹ì„± ë° íƒ€ê¹ƒ ì„¤ì •\n","BASE_FEATURES = ['ê¸°ì˜¨', 'í’í–¥', 'í’ì†', 'ì¼ê°•ìˆ˜ëŸ‰', 'ì‹œê°„ ê°•ìˆ˜ëŸ‰',\n","                 'ìƒëŒ€ ìŠµë„', 'ì¼ì‚¬ëŸ‰', 'ì²´ê°ì˜¨ë„', 'ì‹œê°', 'ìš”ì¼1']\n","TARGET = 'ì—´ìˆ˜ìš”'\n","\n","def create_sequences(X, y=None, timesteps=TIMESTEPS):\n","    Xs, ys = [], []\n","    for i in range(timesteps, len(X)):\n","        Xs.append(X[i - timesteps:i])\n","        if y is not None:\n","            ys.append(y[i])\n","    return np.array(Xs), (np.array(ys) if y is not None else None)\n","\n","def preprocess_data(df, test):\n","    df_train_enc = pd.get_dummies(df, columns=['ì§€ì‚¬ëª…'])\n","    df_val_enc = pd.get_dummies(test, columns=['ì§€ì‚¬ëª…'])\n","    df_val_enc = df_val_enc.reindex(columns=df_train_enc.columns, fill_value=0)\n","\n","    features = [col for col in df_train_enc.columns if col in BASE_FEATURES or col.startswith('ì§€ì‚¬ëª…_')]\n","    X_train, X_val = df_train_enc[features], df_val_enc[features]\n","    y_train, y_val = df_train_enc[TARGET].values, df_val_enc[TARGET].values\n","\n","    scaler = MinMaxScaler()\n","    X_train_scaled = scaler.fit_transform(X_train)\n","    X_val_scaled = scaler.transform(X_val)\n","\n","    return X_train_scaled, X_val_scaled, y_train, y_val, scaler, df_val_enc\n","\n","def build_model(input_shape, hidden_layers=[64, 32], hidden_activation='relu'):\n","    model = Sequential()\n","\n","    # 1. LSTM Block\n","    model.add(Bidirectional(LSTM(LSTM_UNITS, return_sequences=True), input_shape=input_shape))\n","    model.add(Dropout(DROPOUT_RATE))\n","    model.add(Bidirectional(LSTM(LSTM_UNITS // 2, return_sequences=False)))\n","    model.add(Dropout(DROPOUT_RATE * 0.5))\n","\n","    # 2. Dense Hidden Layers (ìœ ì—°í•˜ê²Œ êµ¬ì„±)\n","    for units in hidden_layers:\n","        model.add(Dense(units, activation=hidden_activation))\n","\n","    # 3. Output Layer\n","    model.add(Dense(1))\n","\n","    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=['mae'])\n","    return model\n","\n","\n","def run_model(df, test):\n","    print(\"ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬...\")\n","    X_train_scaled, X_val_scaled, y_train, y_val, scaler, val_processed = preprocess_data(df, test)\n","\n","    print(\"ğŸ”„ ì‹œí€€ìŠ¤ ìƒì„±...\")\n","    X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train)\n","    X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val)\n","\n","    print(\"ğŸ—ï¸ ëª¨ë¸ êµ¬ì¶•...\")\n","    model = build_model((TIMESTEPS, X_train_seq.shape[2]))\n","\n","    print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ...\")\n","    callbacks = [\n","        EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n","        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n","    ]\n","\n","    history = model.fit(\n","        X_train_seq, y_train_seq,\n","        validation_data=(X_val_seq, y_val_seq),\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        callbacks=callbacks,\n","        verbose=1\n","    )\n","\n","    return model, history, scaler, (X_val_scaled, y_val), val_processed, (X_val_seq, y_val_seq)\n","\n","def evaluate_model(model, X_val_seq, y_val_seq):\n","    print(\"ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...\")\n","    y_pred = model.predict(X_val_seq).flatten()\n","    mae = mean_absolute_error(y_val_seq, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_val_seq, y_pred))\n","    r2 = r2_score(y_val_seq, y_pred)\n","\n","    print(f\"ğŸ“ˆ MAE:  {mae:.2f}\")\n","    print(f\"ğŸ“‰ RMSE: {rmse:.2f}\")\n","    print(f\"ğŸ§® RÂ²:   {r2:.4f}\")\n","\n","    return y_pred, mae, rmse, r2\n","\n","def predict_on_test(model, df_test_raw, scaler, reference_df):\n","    df_test_enc = pd.get_dummies(df_test_raw, columns=['ì§€ì‚¬ëª…'])\n","    df_test_enc = df_test_enc.reindex(columns=reference_df.columns, fill_value=0)\n","\n","    features = [col for col in reference_df.columns if col in BASE_FEATURES or col.startswith('ì§€ì‚¬ëª…_')]\n","    X_test = df_test_enc[features]\n","    X_test_scaled = scaler.transform(X_test)\n","\n","    X_test_seq, _ = create_sequences(X_test_scaled, timesteps=TIMESTEPS)\n","    y_pred = model.predict(X_test_seq).flatten()\n","\n","    df_result = df_test_raw.iloc[TIMESTEPS:].copy()\n","    df_result['ì˜ˆì¸¡_ì—´ìˆ˜ìš”'] = y_pred\n","    return df_result\n","\n","# 2. train/validation ë¶„ë¦¬\n","train, val = train_test_split(df, test_size=0.2, shuffle=False)\n","\n","# 3. í•™ìŠµ\n","model, history, scaler, _, val_processed, (X_val_seq, y_val_seq) = run_model(train, val)\n","\n","# 4. í‰ê°€\n","evaluate_model(model, X_val_seq, y_val_seq)\n","\n","# 5. ì˜ˆì¸¡\n","result_df = predict_on_test(model, test, scaler, reference_df=val_processed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvRokU-svQRw","outputId":"ed1cd3bc-dffd-4841-da98-d51004331fc3"},"id":"DvRokU-svQRw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬...\n","ğŸ”„ ì‹œí€€ìŠ¤ ìƒì„±...\n","ğŸ—ï¸ ëª¨ë¸ êµ¬ì¶•...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["ğŸš€ ëª¨ë¸ í•™ìŠµ...\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}